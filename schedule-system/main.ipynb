{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Using cached tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "Collecting tensorflow<2.19,>=2.18\n",
      "  Using cached tensorflow-2.18.0-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.20.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (23.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (69.5.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.31.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.63.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.43.0)\n",
      "Requirement already satisfied: optree in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.12.1)\n",
      "Requirement already satisfied: namex in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: rich in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2024.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n",
      "Installing collected packages: tensorflow, tf-keras\n",
      "Successfully installed tensorflow-2.18.0 tf-keras-2.18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/tf-keras/\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --user tf-keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2023.12.2)\n",
      "Collecting requests>=2.32.2\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (23.2)\n",
      "Collecting huggingface-hub>=0.23.0\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Collecting tqdm>=4.66.3\n",
      "  Downloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.3.1.1)\n",
      "Collecting multiprocess<0.70.17\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-win_amd64.whl (30 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.11.0)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: tqdm, requests, dill, xxhash, multiprocess, huggingface-hub, datasets\n",
      "Successfully installed datasets-3.1.0 dill-0.3.8 huggingface-hub-0.26.2 multiprocess-0.70.16 requests-2.32.3 tqdm-4.66.6 xxhash-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "zenml 0.60.0 requires requests<2.32.0, but you have requests 2.32.3 which is incompatible.\n",
      "mergoo 0.0.9 requires accelerate~=0.27.2, but you have accelerate 0.28.0 which is incompatible.\n",
      "mergoo 0.0.9 requires tqdm==4.66.2, but you have tqdm 4.66.6 which is incompatible.\n",
      "apache-airflow 2.9.1 requires alembic<2.0,>=1.13.1, but you have alembic 1.8.1 which is incompatible.\n",
      "apache-airflow 2.9.1 requires sqlalchemy<2.0,>=1.4.36, but you have sqlalchemy 2.0.31 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\lenovo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install datasets, pydantic, outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM\n",
    "from outlines import models, generate\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify rule and data for finetuning and few-shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 is CN btw\n",
    "rule = \"\"\"\n",
    "A day will start from 7AM to 5PM\n",
    "Early morning is defined as 7-9 AM,\n",
    "Morning is defined as 9-12 AM,\n",
    "Afternoon is defined as 12-3 PM,\n",
    "Evening is defined as 3-5 PM,\n",
    "Do not include days where the customer has a meeting booked.\n",
    "\"\"\"\n",
    "data = [\n",
    "    {\n",
    "        \"input\": {\"customerID\": \"A01\", \"response\": \"I am available every morning from 9.am to 11.am, except on Wednesdays.\"},\n",
    "        \"output\": '{\"customerID\": \"A01\", \"original\": \"I am available every morning from 9.am to 11.am, except on Wednesdays.\", \"available_time\": {\"2\": [9, 10, 11], \"3\": [9, 10, 11], \"4\":[], \"5\": [9, 10, 11], \"6\": [9, 10, 11], \"7\": [9, 10, 11], \"8\": [9, 10, 11]}, \"prefer\": \"None\"}'\n",
    "    },\n",
    "    {\n",
    "        \"input\": {\"customerID\": \"A02\", \"response\": \"I am available every afternoon from 1.pm to 3.pm, except on Fridays.\"},\n",
    "        \"output\": '{\"customerID\": \"A02\", \"original\": \"I am available every afternoon from 1.pm to 3.pm, except on Fridays.\", \"available_time\": {\"2\": [13, 14, 15], \"3\": [13, 14, 15], \"4\": [13, 14, 15], \"5\":[], \"6\": [13, 14, 15], \"7\": [13, 14, 15], \"8\": [13, 14, 15]}, \"prefer\": \"None\"}'\n",
    "    },\n",
    "    {\n",
    "        \"input\": {\"customerID\": \"A03\", \"response\": \"I am available every evening from 6.pm to 8.pm, except on Mondays.\"},\n",
    "        \"output\": '{\"customerID\": \"A03\", \"original\": \"I am available every evening from 6.pm to 8.pm, except on Mondays.\", \"available_time\": {\"2\":[], \"3\": [], \"4\": [], \"5\": [], \"6\": [], \"7\": [], \"8\": []}, \"prefer\": \"None\"}'\n",
    "    },\n",
    "    {\n",
    "        \"input\": {\"customerID\": \"B01\", \"response\": \"I am free on Tuesdays, but if possible, I prefer an early morning slot.\"},\n",
    "        \"output\": '{\"customerID\": \"B01\", \"original\": \"I am free on Tuesdays, but if possible, I prefer an early morning slot.\", \"available_time\": {\"3\": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]}, \"prefer\": {\"3\": [7, 8, 9]}}'\n",
    "    },\n",
    "    {\n",
    "        \"input\": {\"customerID\": \"B02\", \"response\": \"I already have a meeting booked on Friday from 2 to 4 PM.\"},\n",
    "        \"output\": '{\"customerID\": \"B02\", \"original\": \"I already have a meeting booked on Friday from 2 to 4 PM.\", \"available_time\": {\"2\": [7, 8, 9, 10, 11, 12, 13, 17], \"3\": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \"4\": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \"5\": [7, 8, 9, 10, 11, 12, 13, 17], \"6\": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \"7\": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \"8\": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]}, \"prefer\": \"None\"}'\n",
    "    }\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"training_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune model and few-shot learning (Failed, sorry guys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, TextDataset, DataCollatorForLanguageModeling\n",
    "# from transformers import LineByLineTextDataset\n",
    "\n",
    "# # Initialize the GPT-2 model and tokenizer\n",
    "# model_name = \"gpt2\"\n",
    "# model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "# tokenizer.pad_token = tokenizer.eos_token  # Set EOS token as the padding token\n",
    "\n",
    "# # Load the dataset\n",
    "# def load_dataset(file_path):\n",
    "#     # Load the data as line-by-line text for the training format\n",
    "#     return LineByLineTextDataset(tokenizer=tokenizer, file_path=file_path, block_size=128)\n",
    "\n",
    "# # Convert your JSONL data to plain text format for fine-tuning\n",
    "# def convert_jsonl_to_text(jsonl_path, text_output_path):\n",
    "#     with open(jsonl_path, \"r\") as jsonl_file, open(text_output_path, \"w\") as text_file:\n",
    "#         for line in jsonl_file:\n",
    "#             item = eval(line)\n",
    "#             prompt = item[\"input\"]\n",
    "#             output = item[\"output\"]\n",
    "#             # Concatenate prompt and output for training\n",
    "#             combined = f\"{prompt}\\n{output}\\n\\n\"\n",
    "#             text_file.write(combined)\n",
    "\n",
    "# # Paths\n",
    "# jsonl_path = \"training_data.jsonl\"\n",
    "# text_output_path = \"training_data.txt\"\n",
    "# convert_jsonl_to_text(jsonl_path, text_output_path)\n",
    "\n",
    "# # Load the dataset\n",
    "# train_dataset = load_dataset(text_output_path)\n",
    "\n",
    "# # Set up the data collator\n",
    "# data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# # Define training arguments\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./gpt2-finetuned\",\n",
    "#     overwrite_output_dir=True,\n",
    "#     num_train_epochs=3,\n",
    "#     per_device_train_batch_size=2,\n",
    "#     save_steps=500,\n",
    "#     save_total_limit=2,\n",
    "#     prediction_loss_only=True,\n",
    "# )\n",
    "\n",
    "# # Initialize the Trainer\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     data_collator=data_collator,\n",
    "#     train_dataset=train_dataset,\n",
    "# )\n",
    "\n",
    "# # Train the model\n",
    "# trainer.train()\n",
    "\n",
    "# # Save the model and tokenizer\n",
    "# model.save_pretrained(\"./gpt2-finetuned\")\n",
    "# tokenizer.save_pretrained(\"./gpt2-finetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.output_parsers import JsonOutputParser\n",
    "# from langchain_core.prompts import PromptTemplate\n",
    "# from langchain.llms import HuggingFacePipeline\n",
    "# from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "# import json\n",
    "\n",
    "# # Load the fine-tuned model and tokenizer\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"./gpt2-finetuned\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"./gpt2-finetuned\")\n",
    "# hf_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_length=500)\n",
    "\n",
    "# llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
    "\n",
    "# # Define JSON schema for LangChain’s JsonOutputParser\n",
    "# json_schema = {\n",
    "#     \"customerID\": \"string\",\n",
    "#     \"original\": \"string\",\n",
    "#     \"available_time\": {\n",
    "#         \"type\": \"object\",\n",
    "#         \"properties\": {\n",
    "#             \"2\": {\"type\": \"array\", \"items\": {\"type\": \"integer\"}},\n",
    "#             \"3\": {\"type\": \"array\", \"items\": {\"type\": \"integer\"}},\n",
    "#             \"4\": {\"type\": \"array\", \"items\": {\"type\": \"integer\"}},\n",
    "#             \"5\": {\"type\": \"array\", \"items\": {\"type\": \"integer\"}},\n",
    "#             \"6\": {\"type\": \"array\", \"items\": {\"type\": \"integer\"}},\n",
    "#             \"7\": {\"type\": \"array\", \"items\": {\"type\": \"integer\"}},\n",
    "#             \"CN\": {\"type\": \"array\", \"items\": {\"type\": \"integer\"}}\n",
    "#         }\n",
    "#     },\n",
    "#     \"prefer\": \"string\"\n",
    "# }\n",
    "\n",
    "# output_parser = JsonOutputParser(schema=json_schema)\n",
    "\n",
    "# # Define a clearer prompt template for JSON generation\n",
    "# rule = \"\"\"\n",
    "# A day will start from 7AM to 5PM.\n",
    "# Early morning is defined as 7-9 AM,\n",
    "# Morning is defined as 9-12 AM,\n",
    "# Afternoon is defined as 12-3 PM,\n",
    "# Evening is defined as 3-5 PM.\n",
    "# Do not include days where the customer has a meeting booked.\n",
    "# \"\"\"\n",
    "\n",
    "# prompt_template = PromptTemplate(\n",
    "#     input_variables=[\"customerID\", \"response\"],\n",
    "#     template=(\n",
    "#         f\"Rule: {rule.strip()}\\n\\n\"\n",
    "#         \"Customer ID: {customerID}\\n\"\n",
    "#         \"Customer Response: \\\"{response}\\\"\\n\\n\"\n",
    "#         \"Please generate output JSON in the following structure exactly:\\n\"\n",
    "#         \"{{\\n\"\n",
    "#         \"    \\\"customerID\\\": \\\"{customerID}\\\",\\n\"\n",
    "#         \"    \\\"original\\\": \\\"{response}\\\",\\n\"\n",
    "#         \"    \\\"available_time\\\": {{\\\"2\\\": [], \\\"3\\\": [], \\\"4\\\": [], \\\"5\\\": [], \\\"6\\\": [], \\\"7\\\": [], \\\"CN\\\": []}},\\n\"\n",
    "#         \"    \\\"prefer\\\": \\\"None\\\"\\n\"\n",
    "#         \"}}\"\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Function to generate JSON output with error handling\n",
    "# def generate_json_output(customerID, response):\n",
    "#     prompt = prompt_template.format(customerID=customerID, response=response)\n",
    "#     result = llm(prompt)\n",
    "    \n",
    "#     # Extract the text generated by the model\n",
    "#     generated_text = result.strip()\n",
    "\n",
    "#     parsed_output = output_parser.parse(generated_text)\n",
    "\n",
    "\n",
    "#     return parsed_output\n",
    "\n",
    "# # Test with a sample input\n",
    "# customer_id = \"A01\"\n",
    "# response = \"I am available every morning from 9.am to 11.am, except on Wednesdays.\"\n",
    "# output = generate_json_output(customer_id, response)\n",
    "# print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduling algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, i assume that the LLM has already extract the json-string format correctly and beautifully (however it's not, i am fixing it, but i affraid that i can not do it on time). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each user, we will have a json file like this: \n",
    "{\n",
    "    \"customerID\": \"A01\",\n",
    "    \"original\": \"I am available every morning from 9.am to 11.am, except on Wednesdays.\",\n",
    "    \"available_time\": {\n",
    "        \"2\": [9, 10, 11],\n",
    "        \"3\": [9, 10, 11],\n",
    "        \"4\": [],\n",
    "        \"5\": [9, 10, 11],\n",
    "        \"6\": [9, 10, 11],\n",
    "        \"7\": [9, 10, 11],\n",
    "        \"8\": [9, 10, 11]\n",
    "    },\n",
    "    \"prefer\": \"None\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the output of the data above to use in this example because the model i trained fail badly :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the ouput of the model is a string so that we need to convert it to dictionary\n",
    "all_customer = []\n",
    "def convert_str_to_dict(string):\n",
    "    return json.loads(string)\n",
    "for output in df[\"output\"]:\n",
    "    customer_dict = convert_str_to_dict(output)\n",
    "    all_customer.append(customer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'customerID': 'A01',\n",
       "  'original': 'I am available every morning from 9.am to 11.am, except on Wednesdays.',\n",
       "  'available_time': {'2': [9, 10, 11],\n",
       "   '3': [9, 10, 11],\n",
       "   '4': [],\n",
       "   '5': [9, 10, 11],\n",
       "   '6': [9, 10, 11],\n",
       "   '7': [9, 10, 11],\n",
       "   '8': [9, 10, 11]},\n",
       "  'prefer': 'None'},\n",
       " {'customerID': 'A02',\n",
       "  'original': 'I am available every afternoon from 1.pm to 3.pm, except on Fridays.',\n",
       "  'available_time': {'2': [13, 14, 15],\n",
       "   '3': [13, 14, 15],\n",
       "   '4': [13, 14, 15],\n",
       "   '5': [],\n",
       "   '6': [13, 14, 15],\n",
       "   '7': [13, 14, 15],\n",
       "   '8': [13, 14, 15]},\n",
       "  'prefer': 'None'},\n",
       " {'customerID': 'A03',\n",
       "  'original': 'I am available every evening from 6.pm to 8.pm, except on Mondays.',\n",
       "  'available_time': {'2': [],\n",
       "   '3': [],\n",
       "   '4': [],\n",
       "   '5': [],\n",
       "   '6': [],\n",
       "   '7': [],\n",
       "   '8': []},\n",
       "  'prefer': 'None'},\n",
       " {'customerID': 'B01',\n",
       "  'original': 'I am free on Tuesdays, but if possible, I prefer an early morning slot.',\n",
       "  'available_time': {'3': [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]},\n",
       "  'prefer': {'3': [7, 8, 9]}},\n",
       " {'customerID': 'B02',\n",
       "  'original': 'I already have a meeting booked on Friday from 2 to 4 PM.',\n",
       "  'available_time': {'2': [7, 8, 9, 10, 11, 12, 13, 17],\n",
       "   '3': [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
       "   '4': [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
       "   '5': [7, 8, 9, 10, 11, 12, 13, 17],\n",
       "   '6': [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
       "   '7': [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
       "   '8': [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]},\n",
       "  'prefer': 'None'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A01':    7   8   9   10  11  12  13  14  15  16  17\n",
       " 2   0   0   1   1   1   0   0   0   0   0   0\n",
       " 3   0   0   1   1   1   0   0   0   0   0   0\n",
       " 4   0   0   0   0   0   0   0   0   0   0   0\n",
       " 5   0   0   1   1   1   0   0   0   0   0   0\n",
       " 6   0   0   1   1   1   0   0   0   0   0   0\n",
       " 7   0   0   1   1   1   0   0   0   0   0   0\n",
       " 8   0   0   1   1   1   0   0   0   0   0   0}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function will create a dataframe that represents the availability of each customer, it will add 0.01 to each customer time if they prefer it\n",
    "def create_availability_dataframe(customers_data):\n",
    "    # Dictionary to store each customer's availability DataFrame, with customerID as the key\n",
    "    availability_dict = {}\n",
    "\n",
    "    for customer in customers_data:\n",
    "        customer_id = customer['customerID']\n",
    "        available_time = customer['available_time']\n",
    "        prefer = customer['prefer']\n",
    "        \n",
    "        # Initialize individual DataFrame for each customer\n",
    "        df_availability = pd.DataFrame(0, index=range(2, 9), columns=range(7, 18))\n",
    "\n",
    "        for day, hours in available_time.items():\n",
    "            for hour in hours:\n",
    "                # Set availability\n",
    "                df_availability.at[int(day), int(hour)] = 1\n",
    "                \n",
    "                # Check and apply preference if it's a dictionary\n",
    "                if isinstance(prefer, dict) and day in prefer:\n",
    "                    if int(hour) in prefer[day]:\n",
    "                        df_availability.at[int(day), int(hour)] += 0.01\n",
    "        \n",
    "        # Store the DataFrame in the dictionary with customerID as the key\n",
    "        availability_dict[customer_id] = df_availability\n",
    "\n",
    "    return availability_dict\n",
    "demo = create_availability_dataframe([all_customer[0]])\n",
    "demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_12984\\69011362.py:22: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.01' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_availability.at[int(day), int(hour)] += 0.01\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_12984\\69011362.py:22: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.01' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_availability.at[int(day), int(hour)] += 0.01\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_12984\\69011362.py:22: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.01' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_availability.at[int(day), int(hour)] += 0.01\n"
     ]
    }
   ],
   "source": [
    "all_customer_schedule = [create_availability_dataframe([customer]) for customer in all_customer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'A01':    7   8   9   10  11  12  13  14  15  16  17\n",
       "  2   0   0   1   1   1   0   0   0   0   0   0\n",
       "  3   0   0   1   1   1   0   0   0   0   0   0\n",
       "  4   0   0   0   0   0   0   0   0   0   0   0\n",
       "  5   0   0   1   1   1   0   0   0   0   0   0\n",
       "  6   0   0   1   1   1   0   0   0   0   0   0\n",
       "  7   0   0   1   1   1   0   0   0   0   0   0\n",
       "  8   0   0   1   1   1   0   0   0   0   0   0},\n",
       " {'A02':    7   8   9   10  11  12  13  14  15  16  17\n",
       "  2   0   0   0   0   0   0   1   1   1   0   0\n",
       "  3   0   0   0   0   0   0   1   1   1   0   0\n",
       "  4   0   0   0   0   0   0   1   1   1   0   0\n",
       "  5   0   0   0   0   0   0   0   0   0   0   0\n",
       "  6   0   0   0   0   0   0   1   1   1   0   0\n",
       "  7   0   0   0   0   0   0   1   1   1   0   0\n",
       "  8   0   0   0   0   0   0   1   1   1   0   0},\n",
       " {'A03':    7   8   9   10  11  12  13  14  15  16  17\n",
       "  2   0   0   0   0   0   0   0   0   0   0   0\n",
       "  3   0   0   0   0   0   0   0   0   0   0   0\n",
       "  4   0   0   0   0   0   0   0   0   0   0   0\n",
       "  5   0   0   0   0   0   0   0   0   0   0   0\n",
       "  6   0   0   0   0   0   0   0   0   0   0   0\n",
       "  7   0   0   0   0   0   0   0   0   0   0   0\n",
       "  8   0   0   0   0   0   0   0   0   0   0   0},\n",
       " {'B01':      7     8     9   10  11  12  13  14  15  16  17\n",
       "  2  0.00  0.00  0.00   0   0   0   0   0   0   0   0\n",
       "  3  1.01  1.01  1.01   1   1   1   1   1   1   1   1\n",
       "  4  0.00  0.00  0.00   0   0   0   0   0   0   0   0\n",
       "  5  0.00  0.00  0.00   0   0   0   0   0   0   0   0\n",
       "  6  0.00  0.00  0.00   0   0   0   0   0   0   0   0\n",
       "  7  0.00  0.00  0.00   0   0   0   0   0   0   0   0\n",
       "  8  0.00  0.00  0.00   0   0   0   0   0   0   0   0},\n",
       " {'B02':    7   8   9   10  11  12  13  14  15  16  17\n",
       "  2   1   1   1   1   1   1   1   0   0   0   1\n",
       "  3   1   1   1   1   1   1   1   1   1   1   1\n",
       "  4   1   1   1   1   1   1   1   1   1   1   1\n",
       "  5   1   1   1   1   1   1   1   0   0   0   1\n",
       "  6   1   1   1   1   1   1   1   1   1   1   1\n",
       "  7   1   1   1   1   1   1   1   1   1   1   1\n",
       "  8   1   1   1   1   1   1   1   1   1   1   1}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_customer_schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meaning is that after we sum all the customer schedule, we will also get a dataframe with 7x10 (7 days x 10 hours). Each value in this dataframe will be a number ranging from 0 (no customer available at that time) to n_customer*(1.01) (every customer available at that time and like that time). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 3, Time 9: Available Customers - ['A01', 'B01', 'B02']\n",
      "Day 3, Time 10: Available Customers - ['A01', 'B01', 'B02']\n",
      "Day 3, Time 11: Available Customers - ['A01', 'B01', 'B02']\n",
      "Day 3, Time 13: Available Customers - ['A02', 'B01', 'B02']\n",
      "Day 3, Time 14: Available Customers - ['A02', 'B01', 'B02']\n",
      "Day 3, Time 15: Available Customers - ['A02', 'B01', 'B02']\n"
     ]
    }
   ],
   "source": [
    "# We can create a function to select the time slots where at least a certain number of customers are available\n",
    "def find_available_slots(all_customer_schedule, min_customers):\n",
    "    combined_availability = pd.DataFrame(0, index=range(2, 9), columns=range(7, 18))\n",
    "\n",
    "    availability_tracker = {}\n",
    "\n",
    "    for customer_dict in all_customer_schedule:\n",
    "        for customer_id, df in customer_dict.items():\n",
    "            # Add availability data to the combined availability matrix\n",
    "            combined_availability += df\n",
    "            for day, row in df.iterrows():\n",
    "                for time, availability in row.items():\n",
    "                    if availability > 0:  # customer is available at this time slot\n",
    "                        if (day, time) not in availability_tracker:\n",
    "                            availability_tracker[(day, time)] = []\n",
    "                        availability_tracker[(day, time)].append(customer_id)\n",
    "\n",
    "    available_slots = combined_availability[combined_availability >= min_customers].stack()\n",
    "\n",
    "    results = []\n",
    "    for slot in available_slots.index:\n",
    "        day, time = slot\n",
    "        customers = availability_tracker.get((day, time), [])\n",
    "        results.append((day, time, customers))\n",
    "        print(f\"Day {day}, Time {time}: Available Customers - {customers}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "min_customers = 3\n",
    "available_slots = find_available_slots(all_customer_schedule, min_customers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the results, we can see that on tuesdays, at least 3 members can join the meeting from 9am to 11am and 1pm to 3pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 2, Time 9: Available Customers - ['A01', 'B02']\n",
      "Day 2, Time 10: Available Customers - ['A01', 'B02']\n",
      "Day 2, Time 11: Available Customers - ['A01', 'B02']\n",
      "Day 2, Time 13: Available Customers - ['A02', 'B02']\n",
      "Day 3, Time 7: Available Customers - ['B01', 'B02']\n",
      "Day 3, Time 8: Available Customers - ['B01', 'B02']\n",
      "Day 3, Time 9: Available Customers - ['A01', 'B01', 'B02']\n",
      "Day 3, Time 10: Available Customers - ['A01', 'B01', 'B02']\n",
      "Day 3, Time 11: Available Customers - ['A01', 'B01', 'B02']\n",
      "Day 3, Time 12: Available Customers - ['B01', 'B02']\n",
      "Day 3, Time 13: Available Customers - ['A02', 'B01', 'B02']\n",
      "Day 3, Time 14: Available Customers - ['A02', 'B01', 'B02']\n",
      "Day 3, Time 15: Available Customers - ['A02', 'B01', 'B02']\n",
      "Day 3, Time 16: Available Customers - ['B01', 'B02']\n",
      "Day 3, Time 17: Available Customers - ['B01', 'B02']\n",
      "Day 4, Time 13: Available Customers - ['A02', 'B02']\n",
      "Day 4, Time 14: Available Customers - ['A02', 'B02']\n",
      "Day 4, Time 15: Available Customers - ['A02', 'B02']\n",
      "Day 5, Time 9: Available Customers - ['A01', 'B02']\n",
      "Day 5, Time 10: Available Customers - ['A01', 'B02']\n",
      "Day 5, Time 11: Available Customers - ['A01', 'B02']\n",
      "Day 6, Time 9: Available Customers - ['A01', 'B02']\n",
      "Day 6, Time 10: Available Customers - ['A01', 'B02']\n",
      "Day 6, Time 11: Available Customers - ['A01', 'B02']\n",
      "Day 6, Time 13: Available Customers - ['A02', 'B02']\n",
      "Day 6, Time 14: Available Customers - ['A02', 'B02']\n",
      "Day 6, Time 15: Available Customers - ['A02', 'B02']\n",
      "Day 7, Time 9: Available Customers - ['A01', 'B02']\n",
      "Day 7, Time 10: Available Customers - ['A01', 'B02']\n",
      "Day 7, Time 11: Available Customers - ['A01', 'B02']\n",
      "Day 7, Time 13: Available Customers - ['A02', 'B02']\n",
      "Day 7, Time 14: Available Customers - ['A02', 'B02']\n",
      "Day 7, Time 15: Available Customers - ['A02', 'B02']\n",
      "Day 8, Time 9: Available Customers - ['A01', 'B02']\n",
      "Day 8, Time 10: Available Customers - ['A01', 'B02']\n",
      "Day 8, Time 11: Available Customers - ['A01', 'B02']\n",
      "Day 8, Time 13: Available Customers - ['A02', 'B02']\n",
      "Day 8, Time 14: Available Customers - ['A02', 'B02']\n",
      "Day 8, Time 15: Available Customers - ['A02', 'B02']\n"
     ]
    }
   ],
   "source": [
    "min_customers = 2\n",
    "available_slots = find_available_slots(all_customer_schedule, min_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending invitation or verify user is for further investigation. This notebook shows that we can create a scheduling system just like that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
